/**
 * Copyright (C) 2012 LShift Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package net.lshift.diffa.kernel.differencing

import net.lshift.diffa.kernel.config.PairRef
import scala.collection.mutable.{Map => MutableMap}
import org.joda.time.{DateTimeZone, Minutes, DateTime}
import net.lshift.diffa.kernel.util.DateUtils
import net.lshift.diffa.kernel.util.cache.CacheProvider
import scala.collection.JavaConversions._

/**
 * Cache responsible for providing views on aggregated differences.
 *
 * The cache operates using a pair of underlying cache instances - a sequence cache and an aggregate cache. The
 * purposes of the sequence cache is to provide statistics over predictable ranges - as generated by the
 * DifferenceAggregationCachePolicy for a given 'now'. This cache produces validation keys (a combination of the maximum
 * sequence id in a range, and the total count of unmatched differences). The aggregation cache stores time ranged results
 * based upon specific aggregation queries. Each result stores the combined validation key for all sequence cache values
 * that cover it. If a new event arrives (either a mismatch or match), then the appropriate sequence cache (which is
 * calculated based upon 'now' and the event detection time) is invalidated. The next query that arrives will generate
 * a new sequence cache value (which will contain a new validation key) and will thus cause dependent tiles to be
 * marked as invalid and reconstructed.
 */
class DifferenceAggregationCache(diffStore:DomainDifferenceStore, cacheProvider:CacheProvider) {
  val sequenceCache = cacheProvider.getCachedMap[SequenceCacheKey, SequenceCacheValue]("difference.aggregation.sequences")
  val aggregateCache = cacheProvider.getCachedMap[AggregateCacheKey, AggregateCacheValue]("difference.aggregation.values")

  def onStoreUpdate(pair:PairRef, detectionTime:DateTime) = {
    // Remove the stored sequence cache value for the given key
    val k = DifferenceAggregationCachePolicy.sequenceKeyForDetectionTime(pair, now, detectionTime)
    sequenceCache.evict(k)
  }

  def retrieveAggregates(pair:PairRef, start:DateTime, end:DateTime, aggregateMinutes:Option[Int]):Seq[AggregateTile] = {
    if (!DateUtils.safeIsBefore(start, end)) {
      throw new InvalidAggregateRequestException("start time must be before end time")
    }

    // Calculate the time buckets that we're after
    val aggregateBounds = aggregateMinutes match {
      case None    => Seq((start, end))
      case Some(a) => slice(start, end, a)
    }

    // Work through each aggregate, validate and retrieve it. Retain a session between each call to prevent us having
    // to ask the cache for sequence cache keys multiple times
    val session = MutableMap[SequenceCacheKey, SequenceCacheValue]()
    aggregateBounds.map { case ((bStart, bEnd)) => retrieveAggregate(pair, bStart, bEnd, session) }
  }

  def clear() {
    sequenceCache.evictAll()
    aggregateCache.evictAll()
  }

  def retrieveAggregate(pair:PairRef, start:DateTime, end:DateTime, session:MutableMap[SequenceCacheKey, SequenceCacheValue] = MutableMap()) = {
    if (!DateUtils.safeIsBefore(start, end)) {
      throw new InvalidAggregateRequestException("start time must be before end time")
    }

    // Retrieve the sequence cache values that cover this aggregate, then calculate a maximum value
    val seqCacheKeys = DifferenceAggregationCachePolicy.sequenceKeysForDetectionTimeRange(
      pair, now, start, end)
    val cacheEntries = seqCacheKeys.
      map(k => session.getOrElseUpdate(k,
        sequenceCache.readThrough(k, () => retrieveSequenceCacheValue(pair, k.start, k.end))))
    val validationKey = SequenceCacheValue.combine(cacheEntries).toValidationKey

    // Retrieve the value from the aggregate cache, and validate that it matches or exceeds the max sequence id
    val key = AggregateCacheKey(pair, start, end)
    val v = aggregateCache.get(key)
    val value = if (v != null && v.validationKey == validationKey) {
      Some(v)
    } else {
      None
    }

    val count = value match {
      case None    =>
        // Rebuild the value
        val unmatched = diffStore.countUnmatchedEvents(pair, start, end)
        aggregateCache.put(key, AggregateCacheValue(unmatched, validationKey))
        unmatched
      case Some(v) =>
        v.count
    }

    AggregateTile(start, end, count)
  }

  def now = (new DateTime).withZone(DateTimeZone.UTC)

  private def slice(startTime:DateTime, endTime:DateTime, aggregateMinutes:Int) : Seq[(DateTime, DateTime)] = {
    if (startTime == null || endTime == null) {
      throw new InvalidAggregateRequestException("Both a start and end time must be defined when requesting bucketing")
    }

    val divisions = scala.math.ceil(
      Minutes.minutesBetween(startTime, endTime).getMinutes.asInstanceOf[Double] / aggregateMinutes).toInt

    if (startTime.plusMinutes(divisions * aggregateMinutes) != endTime) {
      throw new InvalidAggregateRequestException("Time range %s minutes (%s -> %s) is not a multiple of %s minutes".format(
        Minutes.minutesBetween(startTime, endTime).getMinutes, startTime, endTime, aggregateMinutes))
    }

    (0 to (divisions - 1)).
      map(d => (startTime.plusMinutes(d * aggregateMinutes), startTime.plusMinutes((d + 1) * aggregateMinutes)))
  }

  private def retrieveSequenceCacheValue(pair:PairRef, start:DateTime, end:DateTime):SequenceCacheValue = {
    SequenceCacheValue(diffStore.maxSequenceId(pair, start, end), diffStore.countUnmatchedEvents(pair, start, end))
  }
}

/**
 * Exception indicating that an aggregate request was badly formed.
 */
class InvalidAggregateRequestException(msg:String) extends RuntimeException(msg)

/**
 * Key into the sequence cache for a time range on a given pair.
 */
case class SequenceCacheKey(pair:PairRef, start:DateTime, end:DateTime)

/**
 * Value stored in the sequence cache, representing the max sequence id found in the region along with the total
 * count of differences.
 */
case class SequenceCacheValue(maxSeqId:Long, totalCount:Int) {
  def toValidationKey = maxSeqId + "." + totalCount
}
object SequenceCacheValue {
  def combine(values:Iterable[SequenceCacheValue]) =
    SequenceCacheValue(values.map(_.maxSeqId).max, values.map(_.totalCount).sum)
}

/**
 * Key into the aggregate cache for a time range on a given pair.
 */
case class AggregateCacheKey(pair:PairRef, start:DateTime, end:DateTime)

/**
 * Value stored in the aggregate cache.
 */
case class AggregateCacheValue(count:Int, validationKey:String)

/**
 * A tile containing the count from a given start to end time.
 */
case class AggregateTile(start:DateTime, end:DateTime, count:Int)